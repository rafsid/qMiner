{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: PyPDF2 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (3.0.1)\n",
      "Requirement already satisfied: pytesseract in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (0.3.10)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (0.2.11)\n",
      "Requirement already satisfied: langchain_community in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (0.2.10)\n",
      "Collecting crewai\n",
      "  Downloading crewai-0.41.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from pytesseract) (10.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from langchain) (0.2.25)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from langchain) (0.1.94)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from langchain_community) (0.6.7)\n",
      "Collecting appdirs<2.0.0,>=1.4.4 (from crewai)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from crewai) (8.1.7)\n",
      "Collecting embedchain<0.2.0,>=0.1.114 (from crewai)\n",
      "  Downloading embedchain-0.1.119-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting instructor==1.3.3 (from crewai)\n",
      "  Downloading instructor-1.3.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting json-repair<0.26.0,>=0.25.2 (from crewai)\n",
      "  Downloading json_repair-0.25.3-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting jsonref<2.0.0,>=1.1.0 (from crewai)\n",
      "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.13.3 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from crewai) (1.35.10)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.22.0 (from crewai)\n",
      "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from crewai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from crewai)\n",
      "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from crewai) (1.0.1)\n",
      "Collecting regex<2024.0.0,>=2023.12.25 (from crewai)\n",
      "  Downloading regex-2023.12.25-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docstring-parser<0.17,>=0.16 (from instructor==1.3.3->crewai)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jiter<0.5.0,>=0.4.1 (from instructor==1.3.3->crewai)\n",
      "  Downloading jiter-0.4.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from instructor==1.3.3->crewai) (2.20.1)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from instructor==1.3.3->crewai) (13.7.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.9.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from instructor==1.3.3->crewai) (0.12.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Collecting alembic<2.0.0,>=1.13.1 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting chromadb<0.5.0,>=0.4.24 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting cohere<6.0,>=5.3 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading cohere-5.6.2-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.26.1 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_cloud_aiplatform-1.60.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading gptcache-0.1.43-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading langchain_cohere-0.1.9-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting langchain-openai<0.2.0,>=0.1.7 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting mem0ai<0.0.10,>=0.0.9 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading mem0ai-0.0.9-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting posthog<4.0.0,>=3.0.2 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: tiktoken<0.8.0,>=0.7.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from embedchain<0.2.0,>=0.1.114->crewai) (0.7.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from openai<2.0.0,>=1.13.3->crewai) (4.12.2)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: importlib-metadata<=8.0.0,>=6.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai) (7.2.1)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf<5.0,>=3.19 (from opentelemetry-proto==1.26.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting build>=1.0.3 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (252 bytes)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (0.111.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (0.30.3)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pulsar_client-3.5.0-cp311-cp311-macosx_10_15_universal2.whl.metadata (1.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading onnxruntime-1.18.1-cp311-cp311-macosx_11_0_universal2.whl.metadata (4.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (0.19.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: overrides>=7.3.1 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (6.4.0)\n",
      "Collecting grpcio>=1.58.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpcio-1.65.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.3 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading bcrypt-4.2.0-cp39-abi3-macosx_10_12_universal2.whl.metadata (9.6 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading mmh3-4.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting boto3<2.0.0,>=1.34.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading boto3-1.34.151-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading fastavro-1.9.5-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.5 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai) (1.16.0)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-auth<3.0.0dev,>=2.14.1 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_auth-2.32.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_cloud_storage-2.18.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_cloud_bigquery-3.25.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_cloud_resource_manager-1.12.5-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading shapely-2.0.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: cachetools in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from gptcache<0.2.0,>=0.1.43->embedchain<0.2.0,>=0.1.114->crewai) (5.3.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (0.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai) (3.19.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (3.0.0)\n",
      "Collecting langchain-experimental>=0.0.6 (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading langchain_experimental-0.0.63-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tabulate<0.10.0,>=0.9.0 (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting qdrant-client<2.0.0,>=1.9.1 (from mem0ai<0.0.10,>=0.0.9->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading qdrant_client-1.10.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting monotonic>=1.5 (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.114->crewai) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from rich<14.0.0,>=13.7.0->instructor==1.3.3->crewai) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from rich<14.0.0,>=13.7.0->instructor==1.3.3->crewai) (2.18.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from typer<1.0.0,>=0.9.0->instructor==1.3.3->crewai) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Collecting botocore<1.35.0,>=1.34.151 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading botocore-1.34.151-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (0.0.4)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (3.1.4)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (0.0.9)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (2.2.0)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-cloud-core<3.0.0dev,>=1.6.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=0.6.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_crc32c-1.5.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor==1.3.3->crewai) (0.1.2)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (1.12)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-util-http==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading opentelemetry_util_http-0.47b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (69.5.1)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.10,>=0.0.9->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpcio_tools-1.65.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.10,>=0.0.9->embedchain<0.2.0,>=0.1.114->crewai) (2.10.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (0.23.4)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (12.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.114->crewai) (2.1.5)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (2.6.1)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.10,>=0.0.9->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpcio_tools-1.65.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.64.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.64.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.63.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.62.2-cp311-cp311-macosx_10_10_universal2.whl.metadata (6.2 kB)\n",
      "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.10,>=0.0.9->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (2024.6.1)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/envs/mlx/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (1.3.0)\n",
      "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.10,>=0.0.9->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.10,>=0.0.9->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading crewai-0.41.1-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading instructor-1.3.3-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading embedchain-0.1.119-py3-none-any.whl (209 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.3/209.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading json_repair-0.25.3-py3-none-any.whl (12 kB)\n",
      "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
      "Downloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp311-cp311-macosx_11_0_arm64.whl (291 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp311-cp311-macosx_11_0_arm64.whl (198 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.7/198.7 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cohere-5.6.2-py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading google_cloud_aiplatform-1.60.0-py2.py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gptcache-0.1.43-py3-none-any.whl (131 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.4.2-cp311-cp311-macosx_11_0_arm64.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.3/313.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_cohere-0.1.9-py3-none-any.whl (35 kB)\n",
      "Downloading langchain_openai-0.1.19-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mem0ai-0.0.9-py3-none-any.whl (29 kB)\n",
      "Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
      "Downloading bcrypt-4.2.0-cp39-abi3-macosx_10_12_universal2.whl (472 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.4/472.4 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.34.151-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading fastavro-1.9.5-cp311-cp311-macosx_10_9_universal2.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.32.0-py2.py3-none-any.whl (195 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.5/195.5 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_bigquery-3.25.0-py2.py3-none-any.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_resource_manager-1.12.5-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.9/341.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.18.0-py2.py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.65.2-cp311-cp311-macosx_10_9_universal2.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_experimental-0.0.63-py3-none-any.whl (203 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-4.1.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading onnxruntime-1.18.1-cp311-cp311-macosx_11_0_universal2.whl (15.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl (15 kB)\n",
      "Downloading opentelemetry_util_http-0.47b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pulsar_client-3.5.0-cp311-cp311-macosx_10_15_universal2.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading qdrant_client-1.10.1-py3-none-any.whl (254 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.5-cp311-cp311-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
      "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.151-py3-none-any.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.5.0-cp311-cp311-macosx_10_9_universal2.whl (32 kB)\n",
      "Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl (24 kB)\n",
      "Downloading grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Downloading grpcio_tools-1.62.2-cp311-cp311-macosx_10_10_universal2.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=9ee1d2397f6d32a74502917c534efd9b84c74afdcc9f601117a756ff2b185695\n",
      "  Stored in directory: /Users/rafatsiddiqui/Library/Caches/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: schema, pypika, monotonic, mmh3, flatbuffers, appdirs, types-requests, tabulate, shapely, regex, pysbd, pyproject_hooks, pypdf, pyasn1, pulsar-client, protobuf, parameterized, opentelemetry-util-http, oauthlib, Mako, jsonref, json-repair, jmespath, jiter, hyperframe, humanfriendly, httpx-sse, hpack, grpcio, google-crc32c, fastavro, docstring-parser, deprecated, chroma-hnswlib, bcrypt, asgiref, rsa, requests-oauthlib, pyasn1-modules, proto-plus, posthog, opentelemetry-proto, opentelemetry-api, h2, grpcio-tools, gptcache, googleapis-common-protos, google-resumable-media, coloredlogs, build, botocore, alembic, s3transfer, opentelemetry-semantic-conventions, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, onnxruntime, grpcio-status, google-auth, qdrant-client, opentelemetry-sdk, opentelemetry-instrumentation-asgi, kubernetes, instructor, grpc-google-iam-v1, google-api-core, boto3, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, mem0ai, langchain-openai, google-cloud-core, cohere, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, chromadb, google-cloud-aiplatform, langchain-experimental, langchain-cohere, embedchain, crewai\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2024.5.15\n",
      "    Uninstalling regex-2024.5.15:\n",
      "      Successfully uninstalled regex-2024.5.15\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aider-chat 0.45.1 requires regex==2024.5.15, but you have regex 2023.12.25 which is incompatible.\n",
      "graphrag 0.1.1 requires scipy==1.12.0, but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.5 alembic-1.13.2 appdirs-1.4.4 asgiref-3.8.1 bcrypt-4.2.0 boto3-1.34.151 botocore-1.34.151 build-1.2.1 chroma-hnswlib-0.7.3 chromadb-0.4.24 cohere-5.6.2 coloredlogs-15.0.1 crewai-0.41.1 deprecated-1.2.14 docstring-parser-0.16 embedchain-0.1.119 fastavro-1.9.5 flatbuffers-24.3.25 google-api-core-2.19.1 google-auth-2.32.0 google-cloud-aiplatform-1.60.0 google-cloud-bigquery-3.25.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.12.5 google-cloud-storage-2.18.0 google-crc32c-1.5.0 google-resumable-media-2.7.1 googleapis-common-protos-1.63.2 gptcache-0.1.43 grpc-google-iam-v1-0.13.1 grpcio-1.65.2 grpcio-status-1.62.2 grpcio-tools-1.62.2 h2-4.1.0 hpack-4.0.0 httpx-sse-0.4.0 humanfriendly-10.0 hyperframe-6.0.1 instructor-1.3.3 jiter-0.4.2 jmespath-1.0.1 json-repair-0.25.3 jsonref-1.1.0 kubernetes-30.1.0 langchain-cohere-0.1.9 langchain-experimental-0.0.63 langchain-openai-0.1.19 mem0ai-0.0.9 mmh3-4.1.0 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.18.1 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-exporter-otlp-proto-http-1.26.0 opentelemetry-instrumentation-0.47b0 opentelemetry-instrumentation-asgi-0.47b0 opentelemetry-instrumentation-fastapi-0.47b0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-util-http-0.47b0 parameterized-0.9.0 posthog-3.5.0 proto-plus-1.24.0 protobuf-4.25.4 pulsar-client-3.5.0 pyasn1-0.6.0 pyasn1-modules-0.4.0 pypdf-4.3.1 pypika-0.48.9 pyproject_hooks-1.1.0 pysbd-0.3.4 qdrant-client-1.10.1 regex-2023.12.25 requests-oauthlib-2.0.0 rsa-4.9 s3transfer-0.10.2 schema-0.7.7 shapely-2.0.5 tabulate-0.9.0 types-requests-2.32.0.20240712\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 pandas PyPDF2 pytesseract langchain langchain_community crewai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Ensure you have Tesseract OCR installed and its path set correctly\u001b[39;00m\n\u001b[1;32m     11\u001b[0m pytesseract\u001b[38;5;241m.\u001b[39mpytesseract\u001b[38;5;241m.\u001b[39mtesseract_cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/opt/homebrew/bin/tesseract\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlx/lib/python3.11/site-packages/langchain/llms/__init__.py:545\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 545\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m llms\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;66;03m# If not in interactive env, raise warning.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive_env():\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Ensure you have Tesseract OCR installed and its path set correctly\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/bin/tesseract'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape HTML content\n",
    "def scrape_html(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    projects = []\n",
    "    # Adjust based on the specific structure of the website\n",
    "    for project in soup.find_all('div', class_='project-item'):\n",
    "        title = project.find('h2').text\n",
    "        description = project.find('p', class_='description').text\n",
    "        deadline = project.find('span', class_='deadline').text\n",
    "        projects.append({'Title': title, 'Description': description, 'Deadline': deadline})\n",
    "    return projects\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_pdf_text(url):\n",
    "    response = requests.get(url)\n",
    "    pdf = PdfReader(io.BytesIO(response.content))\n",
    "    text = \"\"\n",
    "    for page in pdf.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to extract text from images using OCR\n",
    "def extract_image_text(url):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(io.BytesIO(response.content))\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    return text\n",
    "\n",
    "# Function to summarize text using LLM\n",
    "def summarize_text(text):\n",
    "    prompt = f\"Summarize the following text: {text}\"\n",
    "    llm = OpenAI(api_key='your_openai_api_key')\n",
    "    summary = llm.generate(prompt)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import LLMChain\n",
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text):\n",
    "    llm = OpenAI(api_key='your_openai_api_key')\n",
    "    chain = LLMChain(llm=llm, prompt=StringPromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"Summarize the following text: {text}\"\n",
    "    ))\n",
    "    summary = chain.run(text=text)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agentic_workflow(url):\n",
    "    tools = [\n",
    "        Tool(name=\"Scrape HTML\", func=scrape_html, description=\"Scrape projects from HTML\"),\n",
    "        Tool(name=\"Extract PDF\", func=extract_pdf_text, description=\"Extract text from PDF\"),\n",
    "        Tool(name=\"Extract Image\", func=extract_image_text, description=\"Extract text from image using OCR\"),\n",
    "        Tool(name=\"Summarize\", func=summarize_text, description=\"Summarize extracted text\")\n",
    "    ]\n",
    "\n",
    "    llm = OpenAI(api_key='your_openai_api_key')\n",
    "    agent = LLMSingleActionAgent(llm_chain=LLMChain(llm=llm, prompt=StringPromptTemplate(\n",
    "        input_variables=[\"input\", \"tools\"],\n",
    "        template=\"Given the URL {input}, choose the appropriate tool to extract project information: {tools}\"\n",
    "    )), allowed_tools=[tool.name for tool in tools])\n",
    "\n",
    "    executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
    "    return executor.run(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crew():\n",
    "    scraper = Agent(\n",
    "        role=\"Web Scraper\",\n",
    "        goal=\"Extract project information from websites\",\n",
    "        backstory=\"Expert in web scraping and data extraction\",\n",
    "        tools=[scrape_html, extract_pdf_text, extract_image_text]\n",
    "    )\n",
    "\n",
    "    analyzer = Agent(\n",
    "        role=\"Data Analyzer\",\n",
    "        goal=\"Analyze and summarize extracted project information\",\n",
    "        backstory=\"Expert in data analysis and summarization\",\n",
    "        tools=[summarize_text]\n",
    "    )\n",
    "\n",
    "    scraping_task = Task(\n",
    "        description=\"Scrape project information from the given URL\",\n",
    "        agent=scraper\n",
    "    )\n",
    "\n",
    "    analysis_task = Task(\n",
    "        description=\"Analyze and summarize the extracted project information\",\n",
    "        agent=analyzer\n",
    "    )\n",
    "\n",
    "    crew = Crew(\n",
    "        agents=[scraper, analyzer],\n",
    "        tasks=[scraping_task, analysis_task]\n",
    "    )\n",
    "\n",
    "    return crew\n",
    "\n",
    "def process_url_with_crew(url):\n",
    "    crew = create_crew()\n",
    "    result = crew.kickoff(url)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Extraction and Analysis Tool\n",
      "====================================\n",
      "Processing URL: https://www.gatesfoundation.org/\n",
      "1. Using Agentic Workflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mlx/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class StringPromptTemplate with abstract method format",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing URL:\u001b[39m\u001b[38;5;124m\"\u001b[39m, url)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. Using Agentic Workflow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m agentic_result \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_agentic_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgentic Workflow Result:\u001b[39m\u001b[38;5;124m\"\u001b[39m, agentic_result)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m2. Using CrewAI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m, in \u001b[0;36mcreate_agentic_workflow\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      2\u001b[0m tools \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     Tool(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScrape HTML\u001b[39m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m=\u001b[39mscrape_html, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScrape projects from HTML\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      4\u001b[0m     Tool(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract PDF\u001b[39m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m=\u001b[39mextract_pdf_text, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract text from PDF\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      5\u001b[0m     Tool(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract Image\u001b[39m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m=\u001b[39mextract_image_text, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract text from image using OCR\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      6\u001b[0m     Tool(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarize\u001b[39m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m=\u001b[39msummarize_text, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarize extracted text\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m ]\n\u001b[1;32m      9\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour_openai_api_key\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m agent \u001b[38;5;241m=\u001b[39m LLMSingleActionAgent(llm_chain\u001b[38;5;241m=\u001b[39mLLMChain(llm\u001b[38;5;241m=\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39m\u001b[43mStringPromptTemplate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGiven the URL \u001b[39;49m\u001b[38;5;132;43;01m{input}\u001b[39;49;00m\u001b[38;5;124;43m, choose the appropriate tool to extract project information: \u001b[39;49m\u001b[38;5;132;43;01m{tools}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m), allowed_tools\u001b[38;5;241m=\u001b[39m[tool\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools])\n\u001b[1;32m     15\u001b[0m executor \u001b[38;5;241m=\u001b[39m AgentExecutor\u001b[38;5;241m.\u001b[39mfrom_agent_and_tools(agent\u001b[38;5;241m=\u001b[39magent, tools\u001b[38;5;241m=\u001b[39mtools, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m executor\u001b[38;5;241m.\u001b[39mrun(url)\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class StringPromptTemplate with abstract method format"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"Project Extraction and Analysis Tool\")\n",
    "    print(\"====================================\")\n",
    "    \n",
    "    while True:\n",
    "        url = input(\"Enter a URL to process (or 'quit' to exit): \")\n",
    "        if url.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        print(\"Processing URL:\", url)\n",
    "        print(\"1. Using Agentic Workflow\")\n",
    "        agentic_result = create_agentic_workflow(url)\n",
    "        print(\"Agentic Workflow Result:\", agentic_result)\n",
    "        \n",
    "        print(\"\\n2. Using CrewAI\")\n",
    "        crew_result = process_url_with_crew(url)\n",
    "        print(\"CrewAI Result:\", crew_result)\n",
    "        \n",
    "        print(\"\\nProcessing complete.\")\n",
    "        print(\"------------------------------------\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
